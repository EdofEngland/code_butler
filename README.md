# ai-clean

`ai-clean` is a CLI toolkit to analyze a codebase, propose scoped cleanup plans, and optionally apply them in a structured way.

## Commands (placeholders for now)
- `/analyze`: scan a path and list findings.
- `/clean`: guided flow for common structural cleanups.
- `/annotate`: target missing or weak docstrings.
- `/organize`: suggest small file moves into clearer folders.
- `/cleanup-advanced`: surface advisory advanced cleanup ideas.
- `/plan`: generate a cleanup plan for a specific finding.
- `/apply`: apply a stored plan with the configured backend.
- `/changes-review`: summarize changes, risks, and test status.

Until implementations land, the commands print placeholder messages but are discoverable via `ai-clean --help`.

## Plan constraints

Plans generated by ai-clean focus on a single concern at a time to keep diffs small and reviewable:
- Docstring and structural findings must stay within a single file; multiple files require separate findings.
- Organize, duplicate, and advanced cleanup findings may involve more files but are still scoped to one category intent.
- Global renames or API-wide changes are disabled by default; plans containing rename steps are rejected unless explicitly enabled in configuration.

If a finding violates these constraints (e.g., a docstring request spanning multiple files), the CLI surfaces an error so you can create smaller, single-purpose findings.

## Test-first policy

Every `/apply` run records test execution details (command, exit code, and logs) and stores them under `.ai-clean/executions/`. The CLI highlights the test result status after each apply and `/changes-review` replays the stored status so reviewers know whether tests ran. If tests fail—or are skipped because the apply failed—the CLI prints the failing command and points to the execution log so you can rerun tests locally before retrying.
