## 1. Implementation
- [x] 1.1 Define ReviewExecutor to consume plan, diff, and execution results.
  - [x] 1.1.1 Update `ai_clean/interfaces.py` so `ReviewExecutor.review_change` accepts a `CleanupPlan` instance (not just the id), plus the diff string and optional `ExecutionResult`.
  - [x] 1.1.2 Create `ai_clean/executors/review.py` defining a `CodexReviewExecutor` that implements the updated protocol and stores a `CodexCompletion` callback.
  - [x] 1.1.3 Export `CodexReviewExecutor` through `ai_clean/executors/__init__.py` so other modules/factories can import it consistently.
- [x] 1.2 Implement review generation using configured review capability while staying read-only.
  - [x] 1.2.1 Add a `_build_prompt(plan, diff, execution_result)` helper that formats the plan title/intent, ordered steps, constraints, diff, and execution/test status into a Codex prompt.
  - [x] 1.2.2 Invoke the injected completion callback with clear JSON instructions (e.g., ask for `summary`, `risks`, `suggested_checks`) and guard against exceptions so failures surface descriptive errors.
  - [x] 1.2.3 Keep the executor read-only by avoiding filesystem or subprocess writes; document this guarantee in the module docstring and via comments.
- [x] 1.3 Return structured summary including risks and suggested checks.
  - [x] 1.3.1 Parse/validate the Codex response into a dictionary with `summary`, `risks`, and `suggested_checks` keys, defaulting to safe values when parsing fails.
  - [x] 1.3.2 Attach diagnostic metadata (prompt text, raw completion) to the returned structure for downstream debugging.
  - [x] 1.3.3 Cover the success and fallback flows with unit tests that stub the completion callback, proving the executor surfaces plan/diff context correctly.
