## 1. Implementation
- [x] 1.1 Add configurable limits for max files and changed lines per plan.
  - [x] 1.1.1 Extend `AiCleanConfig` in `ai_clean/config.py` with `max_plan_files` and `max_plan_lines` integers plus defaults in `load_config`.
  - [x] 1.1.2 Thread the new config values through `plan_from_finding` and advanced analyzer helpers by adding keyword arguments so every planner receives the limit context.
  - [x] 1.1.3 Update tests that construct `AiCleanConfig` (e.g., `tests/test_executor_factories.py`, `tests/test_planner_orchestrator.py`) to supply the new fields.
- [x] 1.2 Enforce limits in planners and advanced analyzer by splitting work when necessary.
  - [x] 1.2.1 In each category planner (`ai_clean/planners/*.py`), ensure the number of files referenced in `CleanupPlan.locations` does not exceed `max_plan_files`; if it does, split into multiple plans or raise a descriptive `PlannerError`.
  - [x] 1.2.2 During plan serialization in `ai_clean/planners/orchestrator.py`, truncate or reject plans whose estimated changed lines exceed `max_plan_lines`, emitting metadata to explain the decision.
  - [x] 1.2.3 Update `ai_clean/analyzers/advanced.py` so `max_suggestions` honors the limits by discarding Codex suggestions referencing too many files/lines and logging the reason.
- [x] 1.3 Verify limit enforcement during planning flows.
  - [x] 1.3.1 Add unit tests for representative planners (large_file, organize, docstring) verifying they split or reject inputs when the new limits are exceeded.
  - [x] 1.3.2 Extend CLI integration tests (`tests/test_cli_clean.py`, `tests/test_cli_plan.py`) to cover limit-triggered messages so the user is informed when large findings are skipped.
